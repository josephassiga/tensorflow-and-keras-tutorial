{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephassiga/tensorflow-and-keras-tutorial/blob/main/W3/Lab5/W3_Lab_1_intro_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjwVLV2j8yb4"
      },
      "source": [
        "# Natural Language Processing (NLP)\n",
        "\n",
        "NLP is about: using machine learning and large datasets to\n",
        "give computers the ability not to understand language, which is a more lofty goal, but to ingest a piece of language as input and return something useful, like predicting the following:\n",
        "\n",
        "*  What’s the topic of this text?: text classification.\n",
        "*  Does this text contain abuse?: content filtering.\n",
        "*  Does this text sound positive or negative?: sentiment analysis.\n",
        "*  What should be the next word in this incomplete sentence?: language modeling\n",
        "*  How would you say this in German?: translation.\n",
        "*  How would you summarize this article in one paragraph?” : summarization.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn_Y_9Ye8ltW"
      },
      "source": [
        "# Preparing text data\n",
        "\n",
        "Deep learning models, being differentiable functions, can only process numeric tensors: they can’t take raw text as input. Vectorizing text is the process of transforming text into numeric tensors :\n",
        "\n",
        "* First, you standardize the text to make it easier to process, such as by converting it to lowercase or removing punctuation.\n",
        "* You split the text into units (called tokens), such as characters, words, or groups of words. This is called tokenization.\n",
        "* You convert each such token into a numerical vector. This will usually involve\n",
        "first indexing all tokens present in the data.\n",
        "\n",
        "Let's review each of these steps:\n",
        "\n",
        "![From raw text to vectors](images/text-vectorization.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a_xztRmY2Ka"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7qMN9hXBPMm"
      },
      "source": [
        "Now inspecting the data of the Jena weather dataset"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOgju/WK0XBRJbec3zTIfB8",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
